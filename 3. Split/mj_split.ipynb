{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10dfbbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de4db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stm_dir = 'path/to/your/data/mj output'\n",
    "audio_dir = 'path/to/your/data//MJ/wav'\n",
    "output_dir = './mj output/split_audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbfb40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utterances_stm(stm_path):\n",
    "    utterances = []\n",
    "\n",
    "    with open(stm_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=6)\n",
    "            file_id, _, speaker, start, end, _ = parts[:6]\n",
    "            text = parts[6] if len(parts) > 6 else ''\n",
    "\n",
    "            utterances.append({\n",
    "                'id': file_id,\n",
    "                'text': text,\n",
    "                'from': float(start),\n",
    "                'to': float(end),\n",
    "                'speaker': speaker\n",
    "            })\n",
    "\n",
    "    return utterances\n",
    "\n",
    "def get_utterances_audacity(aud_path):\n",
    "    with open(aud_path, 'r') as _f:\n",
    "        lines = _f.readlines()\n",
    "    utterances = []\n",
    "    for line in lines:\n",
    "        components = line.split('\\t')\n",
    "        text = components[2].strip()\n",
    "        utterances.append({'text': text,\n",
    "                           'from': float(components[0]),\n",
    "                           'to': float(components[1])})\n",
    "    return utterances\n",
    "\n",
    "\n",
    "def get_partial_audio(audio_file_path, from_sec, to_sec):\n",
    "    audio = AudioSegment.from_wav(audio_file_path)\n",
    "    audio = audio.set_channels(1).set_frame_rate(16000)\n",
    "    segment = audio[from_sec * 1000 : (to_sec * 1000 + 300)] #manually adding 300ms since words tend to get cut off otherwise\n",
    "    return segment\n",
    "\n",
    "def write_audio(file_path, audio_segment):\n",
    "    audio_segment.export(file_path, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46de590b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing individual utterance audio files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3369/3369 [05:29<00:00, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reference transcript file...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audio_files = glob.glob(f'{audio_dir}/*.wav')\n",
    "transcript_files = glob.glob(f'{stm_dir}/*.stm')\n",
    "all_utterances = {}\n",
    "\n",
    "for af in audio_files:\n",
    "    c_id = os.path.splitext(os.path.basename(af))[0]\n",
    "    single_transcript_path = f'{stm_dir}/{c_id}.stm'\n",
    "    utterances = get_utterances_stm(single_transcript_path)\n",
    "\n",
    "    for idx, u in enumerate(utterances):\n",
    "        utt_id = f\"{c_id}_u{idx}\"\n",
    "        all_utterances[utt_id] = {\n",
    "            'file_id': u['id'],\n",
    "            'text': u['text'],\n",
    "            'audio_file': af,\n",
    "            'from_sec': u['from'],\n",
    "            'to_sec': u['to'],  \n",
    "            'speaker': u['speaker']\n",
    "        }\n",
    "\n",
    "print('Writing individual utterance audio files...')\n",
    "utterance_audio_folder = os.path.join(output_dir, 'audio_utterances')\n",
    "os.makedirs(utterance_audio_folder, exist_ok=True)\n",
    "for utt_id, utt in tqdm(all_utterances.items()):\n",
    "    utt_audio = get_partial_audio(utt['audio_file'],\n",
    "                                    utt['from_sec'],\n",
    "                                    utt['to_sec'])\n",
    "    if utt['speaker'] == 'inter_segment_gap':\n",
    "        utt_id = f'{utt_id}_SIL'\n",
    "    write_audio(os.path.join(utterance_audio_folder, f'{utt_id}.wav'),\n",
    "                utt_audio)\n",
    "    \n",
    "print('Writing reference transcript file...')\n",
    "reference_transcript_path = os.path.join(output_dir,\n",
    "                                            'PR_reference.stm')\n",
    "with open(reference_transcript_path, 'w') as f:\n",
    "    for utt_id, utt in all_utterances.items():\n",
    "        if len(utt['text']) > 0:\n",
    "            f.write(f\"{utt['file_id']} 1 {utt['speaker']} {utt['from_sec']} {utt['to_sec']} <o,f0,unknown> {utt['text']}\\n\")\n",
    "        else:\n",
    "            f.write(f\"({utt['file_id']}\\n\")\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
