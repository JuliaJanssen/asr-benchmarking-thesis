{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf54d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "from collections import Counter\n",
    "from typing import List, Callable, Dict\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import wave\n",
    "import contextlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33932647",
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_path = r\"path/to/your/data/ja/audio\" ###\n",
    "cv_path = r\"path/to/your/data/cv/audio\" ###\n",
    "\n",
    "ja_ref = r\"path/to/your/data/reference/JA_reference.stm\" ###\n",
    "cv_ref = r\"path/to/your/data/reference/CV_reference.stm\" ###\n",
    "\n",
    "out_path = r\"path/to/your/data/selection\" ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_stm_file(file_path):\n",
    "    segments = []\n",
    "    dataset_name = os.path.basename(file_path)\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 6:\n",
    "                continue\n",
    "            file_name = parts[0]\n",
    "            speaker = parts[2]\n",
    "            if speaker == 'inter_segment_gap':\n",
    "                continue\n",
    "            \n",
    "            start_time = float(parts[3])\n",
    "            end_time = float(parts[4])\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            segments.append({\n",
    "                'dataset': dataset_name,\n",
    "                'file': file_name,\n",
    "                'start': start_time,\n",
    "                'end': end_time,\n",
    "                'duration': duration\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a66c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins = [\n",
    "    (\"under ten\", 0, 9),\n",
    "    (\"teens\", 10, 19),\n",
    "    (\"twenties\", 20, 29),\n",
    "    (\"thirties\", 30, 39),\n",
    "    (\"fourties\", 40, 49),\n",
    "    (\"fifties\", 50, 59),\n",
    "    (\"sixties\", 60, 69),\n",
    "    (\"seventies\", 70, 79),\n",
    "    (\"eighties\", 80, 89)\n",
    "]\n",
    "\n",
    "gender_bins = {\n",
    "    \"male\": [\"male\", \"m\"],\n",
    "     \"female\": [\"female\", \"f\"]\n",
    "}\n",
    "\n",
    "\n",
    "def map_to_age_bin(age_str):\n",
    "    if age_str is None or age_str == \"unknown\":\n",
    "        return None\n",
    "\n",
    "    #direct match for common voice labels like \"twenties\"\n",
    "    for label, _, _ in age_bins:\n",
    "        if label in age_str:\n",
    "            return label\n",
    "\n",
    "    #match for jasmin age float values\n",
    "    try:\n",
    "        age = float(age_str)\n",
    "        for label, min_age, max_age in age_bins:\n",
    "            if min_age <= age <= max_age:\n",
    "                return label\n",
    "    except ValueError:\n",
    "        pass \n",
    "\n",
    "    return None  #couldn't determine\n",
    "\n",
    "\n",
    "def map_to_gender_bin(gender_str):\n",
    "    for key, aliases in gender_bins.items():\n",
    "        if gender_str.lower() in aliases:\n",
    "            return key\n",
    "    return None  #couldn't determine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c2cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_dataset_type(ref_path):\n",
    "    filename = ref_path.lower()\n",
    "    if \"cv_\" in filename:\n",
    "        return \"cv\"\n",
    "    elif \"ja_\" in filename:\n",
    "        return \"ja\"\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot infer dataset type from path: {ref_path}\")\n",
    "    \n",
    "    \n",
    "def get_national_variant(filename):\n",
    "    if filename.startswith((\"JApnl\", \"JAqnl\")):\n",
    "        return \"dutch\"\n",
    "    elif filename.startswith((\"JApvl\", \"JAqvl\")):\n",
    "        return \"flemish\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c81f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata(metadata_str, dataset_type, filename):\n",
    "    def clean(val):\n",
    "        val = val.strip().lower() if val else None\n",
    "        return val\n",
    "\n",
    "    if dataset_type == \"cv\":\n",
    "        age, gender, accent = (metadata_str + [None]*3)[:3] #if even one is missing, we can skip it\n",
    "        return {\n",
    "            \"age\": clean(age),\n",
    "            \"gender\": clean(gender),\n",
    "            \"accent\": clean(accent)\n",
    "        }\n",
    "\n",
    "    elif dataset_type == \"ja\":\n",
    "        national_variant = get_national_variant(filename)\n",
    "\n",
    "        gender, age, first_language, proficiency, accent_region = metadata_str\n",
    "        return {\n",
    "            \"gender\": clean(gender),\n",
    "            \"age\": clean(age),\n",
    "            \"national_variant\": clean(national_variant),\n",
    "            \"first_language\": clean(first_language),\n",
    "            \"proficiency\": clean(proficiency),\n",
    "            \"accent_region\": clean(accent_region)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_reference_file(ref_path):\n",
    "    dataset_type = infer_dataset_type(ref_path)\n",
    "    parsed_entries = []\n",
    "\n",
    "    with open(ref_path, 'r', encoding='utf-8') as infile:\n",
    "\n",
    "        for line in infile:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 6:\n",
    "                continue\n",
    "\n",
    "            filename = parts[0]\n",
    "            speaker = parts[2]\n",
    "            speaker_data = parts[5]\n",
    "            start, end = float(parts[3]), float(parts[4])\n",
    "            duration = end - start\n",
    "\n",
    "            if duration < 1 or duration > 20:\n",
    "                continue\n",
    "\n",
    "            if speaker == \"inter_segment_gap\":\n",
    "                continue\n",
    "\n",
    "            speaker_data = speaker_data.lower().strip(\"<>\").split(\",\")\n",
    "            if len(speaker_data) < 3:\n",
    "                continue\n",
    "            \n",
    "            parsed_data = parse_metadata(speaker_data, dataset_type, filename)\n",
    "            \n",
    "            age_bin = map_to_age_bin(parsed_data[\"age\"])\n",
    "            gender_bin = map_to_gender_bin(parsed_data[\"gender\"])\n",
    "            national_variant = parsed_data.get(\"national_variant\")\n",
    "            accent = parsed_data.get(\"accent\") or parsed_data.get(\"accent_region\")\n",
    "            first_language = parsed_data.get(\"first_language\")\n",
    "            proficiency = parsed_data.get(\"proficiency\")\n",
    "\n",
    "            if age_bin is None or gender_bin is None or accent == 'unknown':\n",
    "                continue\n",
    "\n",
    "            parsed_entries.append({\n",
    "                \"filename\": filename,\n",
    "                \"speaker\": speaker,\n",
    "                \"duration\": duration,\n",
    "                \"age_bin\": age_bin,\n",
    "                \"gender_bin\": gender_bin,\n",
    "                \"national_variant\": national_variant,\n",
    "                \"first_language\": first_language,\n",
    "                \"proficiency\": proficiency,\n",
    "                \"accent\": accent,\n",
    "                \"dataset_type\": dataset_type\n",
    "            })\n",
    "\n",
    "    return parsed_entries\n",
    "\n",
    "ja_data = parse_reference_file(ja_ref)\n",
    "cv_data = parse_reference_file(cv_ref)\n",
    "\n",
    "all_data = ja_data + cv_data\n",
    "\n",
    "ja_read_data = [entry for entry in ja_data if entry['filename'].startswith('JAq')]\n",
    "ja_spon_data = [entry for entry in ja_data if entry['filename'].startswith('JAp')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c967591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this tries to get a balanced distribution of age -> gender -> first language category -> read/spontaneous\n",
    "#it first assembles a key for each combination and tries to select perfectly balanced to fill the total_duration\n",
    "#if a shortfall remains it will try again, focusing on the underrepresented categories\n",
    "def balanced_hierarchical_split(\n",
    "\tdata,\n",
    "\ttotal_duration,\n",
    "\tcondition_var=None,\n",
    "\tseed=42,\n",
    "\tused_ids=None,\n",
    "\ttolerance=0.2\n",
    "):\n",
    "\trandom.seed(seed)\n",
    "\ttotal_duration *= 3600 #convert to seconds\n",
    "\n",
    "\tif used_ids is None:\n",
    "\t\tused_ids = set()\n",
    "\n",
    "\t#group by age_bin\n",
    "\tage_bins = defaultdict(list)\n",
    "\tfor utt in data:\n",
    "\t\tif 'age_bin' not in utt or 'gender_bin' not in utt:\n",
    "\t\t\traise ValueError(f\"Utterance missing required fields: {utt}\")\n",
    "\t\tage_bins[utt['age_bin']].append(utt)\n",
    "\n",
    "\tnum_age_bins = len(age_bins)\n",
    "\ttarget_per_age = total_duration / num_age_bins\n",
    "\n",
    "\tselected = []\n",
    "\tshortfall = 0\n",
    "\n",
    "\tfor age_bin, utts_in_age in age_bins.items():\n",
    "\t\tdef get_key(utt):\n",
    "\t\t\tkey = utt['gender_bin']\n",
    "\t\t\tif 'national_variant' in utt:\n",
    "\t\t\t\tkey += f\"|{utt['national_variant']}\"\n",
    "\t\t\tif condition_var and condition_var in utt:\n",
    "\t\t\t\tkey += f\"|{utt[condition_var]}\"\n",
    "\t\t\treturn key\n",
    "\n",
    "\t\tstrata = defaultdict(list)\n",
    "\t\tfor utt in utts_in_age:\n",
    "\t\t\tstrata[get_key(utt)].append(utt)\n",
    "\n",
    "\t\tnum_strata = len(strata)\n",
    "\t\ttarget_per_stratum = target_per_age / num_strata\n",
    "\t\tmin_duration = target_per_stratum * (1 - tolerance)\n",
    "\t\tmax_duration = target_per_stratum * (1 + tolerance)\n",
    "\n",
    "\t\tacc_duration_age_bin = 0\n",
    "\n",
    "\t\tfor stratum_key, utts in strata.items():\n",
    "\t\t\tutts = utts.copy()\n",
    "\t\t\trandom.shuffle(utts)\n",
    "\t\t\tacc_duration_stratum = 0\n",
    "\t\t\tfor utt in utts:\n",
    "\t\t\t\tif utt['filename'] in used_ids:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tif acc_duration_stratum >= max_duration:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tselected.append(utt)\n",
    "\t\t\t\tused_ids.add(utt['filename'])\n",
    "\t\t\t\tacc_duration_stratum += utt['duration']\n",
    "\t\t\tacc_duration_age_bin += acc_duration_stratum\n",
    "\t\t\t#if acc_duration_stratum < min_duration:\n",
    "\t\t\t#\tprint(f\"Warning: Stratum {stratum_key} in age_bin {age_bin} underfilled ({acc_duration_stratum:.1f}s)\")\n",
    "\n",
    "\t\tif acc_duration_age_bin < target_per_age:\n",
    "\t\t\tshortfall += (target_per_age - acc_duration_age_bin)\n",
    "\n",
    "\t#redistribute shortfall\n",
    "\tif shortfall > 0:\n",
    "\t\tprint(f\"Redistributing shortfall of {shortfall:.1f}s\")\n",
    "\n",
    "\t\tremaining_bins = [age_bin for age_bin in age_bins if sum(u['duration'] for u in age_bins[age_bin]) > target_per_age]\n",
    "\t\tif not remaining_bins:\n",
    "\t\t\tprint(\"No bins available for redistribution.\")\n",
    "\t\telse:\n",
    "\t\t\tredistributed_target = shortfall / len(remaining_bins)\n",
    "\n",
    "\t\t\tfor age_bin in remaining_bins:\n",
    "\t\t\t\tdef get_key(utt):\n",
    "\t\t\t\t\tkey = utt['gender_bin']\n",
    "\t\t\t\t\tif 'national_variant' in utt:\n",
    "\t\t\t\t\t\tkey += f\"|{utt['national_variant']}\"\n",
    "\t\t\t\t\tif condition_var and condition_var in utt:\n",
    "\t\t\t\t\t\tkey += f\"|{utt[condition_var]}\"\n",
    "\t\t\t\t\treturn key\n",
    "\n",
    "\t\t\t\tstrata = defaultdict(list)\n",
    "\t\t\t\tfor utt in age_bins[age_bin]:\n",
    "\t\t\t\t\tstrata[get_key(utt)].append(utt)\n",
    "\n",
    "\t\t\t\tnum_strata = len(strata)\n",
    "\t\t\t\ttarget_per_stratum = redistributed_target / num_strata\n",
    "\t\t\t\tmin_duration = target_per_stratum * (1 - tolerance)\n",
    "\t\t\t\tmax_duration = target_per_stratum * (1 + tolerance)\n",
    "\n",
    "\t\t\t\tfor stratum_key, utts in strata.items():\n",
    "\t\t\t\t\tutts = utts.copy()\n",
    "\t\t\t\t\trandom.shuffle(utts)\n",
    "\t\t\t\t\tacc_duration_stratum = 0\n",
    "\t\t\t\t\tfor utt in utts:\n",
    "\t\t\t\t\t\tif utt['filename'] in used_ids:\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t\tif acc_duration_stratum >= max_duration:\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\tselected.append(utt)\n",
    "\t\t\t\t\t\tused_ids.add(utt['filename'])\n",
    "\t\t\t\t\t\tacc_duration_stratum += utt['duration']\n",
    "\t\t\t\t\t#if acc_duration_stratum < min_duration:\n",
    "\t\t\t\t\t#\tprint(f\"Warning: Stratum {stratum_key} in age_bin {age_bin} underfilled ({acc_duration_stratum:.1f}s)\")\n",
    "\n",
    "\ttotal_selected = sum(u['duration'] for u in selected)\n",
    "\tprint(f\"Selected total: {total_selected:.1f}s ({total_selected/3600:.2f}h)\")\n",
    "\n",
    "\treturn selected, used_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c2a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redistributing shortfall of 3442.2s\n",
      "Selected total: 33128.3s (9.20h)\n",
      "Redistributing shortfall of 7938.6s\n",
      "Selected total: 32719.0s (9.09h)\n",
      "Redistributing shortfall of 8573.6s\n",
      "Selected total: 22192.0s (6.16h)\n",
      "Redistributing shortfall of 4463.7s\n",
      "Selected total: 16505.4s (4.58h)\n",
      "Redistributing shortfall of 10449.2s\n",
      "Selected total: 39633.5s (11.01h)\n",
      "Redistributing shortfall of 16010.5s\n",
      "Selected total: 32692.2s (9.08h)\n"
     ]
    }
   ],
   "source": [
    "used_ids = set()\n",
    "\n",
    "def ja_non_native(data):\n",
    "    return [utt for utt in data if utt.get(\"first_language\") not in [\"dut\", \"tus\", \"dia\"]]\n",
    "\n",
    "def ja_native(data):\n",
    "    return [utt for utt in data if utt.get(\"first_language\") in [\"dut\", \"tus\", \"dia\"]]\n",
    "\n",
    "def cv_native(data):\n",
    "    return [utt for utt in data if utt.get(\"accent\").lower() == \"nederlands-nederlands\"]\n",
    "\n",
    "Set0, used_ids = balanced_hierarchical_split(\n",
    "        cv_native(cv_data),\n",
    "        total_duration=10.0,\n",
    "        used_ids=used_ids\n",
    "        )\n",
    "\n",
    "set1, used_ids = balanced_hierarchical_split(\n",
    "        ja_non_native(ja_read_data),\n",
    "        total_duration=9.0, \n",
    "        used_ids=used_ids\n",
    "        )\n",
    "\n",
    "set2, used_ids = balanced_hierarchical_split(\n",
    "        ja_native(ja_read_data), \n",
    "        total_duration=9.0, \n",
    "        condition_var=\"accent\", \n",
    "        used_ids=used_ids\n",
    "        )\n",
    "\n",
    "set3, used_ids = balanced_hierarchical_split(\n",
    "        ja_non_native(ja_spon_data), \n",
    "        total_duration=7.0, \n",
    "        used_ids=used_ids\n",
    "        )\n",
    "\n",
    "set4, used_ids = balanced_hierarchical_split(\n",
    "        ja_native(ja_spon_data), \n",
    "        total_duration=5.0,\n",
    "        condition_var=\"accent\", \n",
    "        used_ids=used_ids\n",
    "        )\n",
    "\n",
    "set6, used_ids = balanced_hierarchical_split(\n",
    "       cv_data,\n",
    "       total_duration=10.0,\n",
    "       used_ids=used_ids\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a0a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stm_and_copy_audio(selected_set, ref_file, out_dir, ref_name, audio_dir):\n",
    "    #generates a stm reference file for the new set, plus copies the selected audio files to a folder\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    out_dir = os.path.join(out_path, out_dir)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    #load reference lines\n",
    "    with open(ref_file, 'r') as f:\n",
    "     ref_transcripts = f.readlines()\n",
    "\n",
    "    print(f\"Loaded {len(ref_transcripts)} reference lines.\")\n",
    "\n",
    "    #create stm file\n",
    "    stm_file_path = os.path.join(out_dir, f\"{ref_name}.stm\")\n",
    "    matched_transcripts = 0\n",
    "    missing_transcripts = 0\n",
    "    missing_audio_files = 0\n",
    "\n",
    "    with open(stm_file_path, 'w') as stm_file:\n",
    "     for utt in selected_set:     \n",
    "       #find matching transcript\n",
    "       transcript = next((line for line in ref_transcripts if line.startswith(utt['filename'])), None)\n",
    "       if transcript:\n",
    "              stm_file.write(transcript)\n",
    "              matched_transcripts += 1\n",
    "       else:\n",
    "              print(f\"Warning: No transcript found for {utt['filename']}\")\n",
    "              missing_transcripts += 1\n",
    "\n",
    "       #copy audio file\n",
    "       audio_file_path = os.path.join(audio_dir, utt['filename']+ \".wav\")\t\n",
    "       if os.path.exists(audio_file_path):\n",
    "              shutil.copy(audio_file_path, out_dir)\n",
    "       else:\n",
    "              print(f\"Warning: No audio file found for {utt['filename']} in {audio_dir}\")\n",
    "              missing_audio_files += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\".stm file and audio files for {out_dir} generated successfully.\")\n",
    "    print(f\"Processed {len(selected_set)} utterances.\")\n",
    "    print(f\"Matched {matched_transcripts} transcripts.\")\n",
    "    print(f\"Missing {missing_transcripts} transcripts.\")\n",
    "    print(f\"Missing {missing_audio_files} audio files.\")\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3f251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 201394 reference transcripts.\n",
      ".stm file and audio files for C:\\Users\\Topicus\\Documents\\Datasets\\selection\\1. nonnative-read generated successfully.\n",
      "Processed 16271 utterances.\n",
      "Matched 16271 transcripts.\n",
      "Missing 0 transcripts.\n",
      "Missing 0 audio files.\n",
      "Elapsed time: 569.12 seconds.\n",
      "Loaded 201394 reference transcripts.\n",
      ".stm file and audio files for C:\\Users\\Topicus\\Documents\\Datasets\\selection\\2. native-read generated successfully.\n",
      "Processed 16012 utterances.\n",
      "Matched 16012 transcripts.\n",
      "Missing 0 transcripts.\n",
      "Missing 0 audio files.\n",
      "Elapsed time: 730.92 seconds.\n",
      "Loaded 201394 reference transcripts.\n",
      ".stm file and audio files for C:\\Users\\Topicus\\Documents\\Datasets\\selection\\3. nonnative-spon generated successfully.\n",
      "Processed 12199 utterances.\n",
      "Matched 12199 transcripts.\n",
      "Missing 0 transcripts.\n",
      "Missing 0 audio files.\n",
      "Elapsed time: 227.86 seconds.\n",
      "Loaded 201394 reference transcripts.\n",
      ".stm file and audio files for C:\\Users\\Topicus\\Documents\\Datasets\\selection\\4. native-spon generated successfully.\n",
      "Processed 9076 utterances.\n",
      "Matched 9076 transcripts.\n",
      "Missing 0 transcripts.\n",
      "Missing 0 audio files.\n",
      "Elapsed time: 166.25 seconds.\n",
      "Loaded 54239 reference transcripts.\n",
      ".stm file and audio files for C:\\Users\\Topicus\\Documents\\Datasets\\selection\\0. baseline generated successfully.\n",
      "Processed 9109 utterances.\n",
      "Matched 9109 transcripts.\n",
      "Missing 0 transcripts.\n",
      "Missing 0 audio files.\n",
      "Elapsed time: 162.90 seconds.\n",
      "Loaded 54239 reference transcripts.\n",
      ".stm file and audio files for C:\\Users\\Topicus\\Documents\\Datasets\\selection\\6. hallucination mix/speech generated successfully.\n",
      "Processed 7624 utterances.\n",
      "Matched 7624 transcripts.\n",
      "Missing 0 transcripts.\n",
      "Missing 0 audio files.\n",
      "Elapsed time: 132.40 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Topicus\\\\Documents\\\\Datasets\\\\selection\\\\6. hallucination mix/speech\\\\6_reference.stm'"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_stm_and_copy_audio(set1, ja_ref, '1. nonnative-read', '1_reference', ja_path)\n",
    "generate_stm_and_copy_audio(set2, ja_ref, '2. native-read', '2_reference', ja_path)\n",
    "generate_stm_and_copy_audio(set3, ja_ref, '3. nonnative-spon', '3_reference', ja_path)\n",
    "generate_stm_and_copy_audio(set4, ja_ref, '4. native-spon', '4_reference', ja_path)\n",
    "generate_stm_and_copy_audio(Set0, cv_ref, '0. baseline', '0_reference', cv_path)\n",
    "generate_stm_and_copy_audio(set6, cv_ref, '6. hallucination mix/speech', '6_reference', cv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee6970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subfolder: 0. baseline\n",
      "  unique: 0 files failed\n",
      "  format: 0 files failed\n",
      "  channels: 0 files failed\n",
      "  rate: 0 files failed\n",
      "  transcript: 0 files failed\n",
      "  Total files checked: 9109\n",
      "\n",
      "Subfolder: 1. nonnative-read\n",
      "  unique: 0 files failed\n",
      "  format: 0 files failed\n",
      "  channels: 0 files failed\n",
      "  rate: 0 files failed\n",
      "  transcript: 0 files failed\n",
      "  Total files checked: 16271\n",
      "\n",
      "Subfolder: 2. native-read\n",
      "  unique: 0 files failed\n",
      "  format: 0 files failed\n",
      "  channels: 0 files failed\n",
      "  rate: 0 files failed\n",
      "  transcript: 0 files failed\n",
      "  Total files checked: 16012\n",
      "\n",
      "Subfolder: 3. nonnative-spon\n",
      "  unique: 0 files failed\n",
      "  format: 0 files failed\n",
      "  channels: 0 files failed\n",
      "  rate: 0 files failed\n",
      "  transcript: 0 files failed\n",
      "  Total files checked: 12199\n",
      "\n",
      "Subfolder: 4. native-spon\n",
      "  unique: 0 files failed\n",
      "  format: 0 files failed\n",
      "  channels: 0 files failed\n",
      "  rate: 0 files failed\n",
      "  transcript: 0 files failed\n",
      "  Total files checked: 9076\n",
      "\n",
      "Subfolder: 5. hallucination noise\n",
      "  unique: 0 files failed\n",
      "  format: 0 files failed\n",
      "  channels: 0 files failed\n",
      "  rate: 0 files failed\n",
      "  transcript: 0 files failed\n",
      "  Total files checked: 2472\n",
      "\n",
      "Subfolder: 6. hallucination mix\n",
      "  unique: 0 files failed\n",
      "  format: 0 files failed\n",
      "  channels: 0 files failed\n",
      "  rate: 0 files failed\n",
      "  transcript: 0 files failed\n",
      "  Total files checked: 2472\n",
      "\n",
      "Subfolder: 7. medical-nl\n",
      "  unique: 0 files failed\n",
      "  format: 0 files failed\n",
      "  channels: 0 files failed\n",
      "  rate: 0 files failed\n",
      "  transcript: 0 files failed\n",
      "  Total files checked: 2527\n",
      "\n",
      "Subfolder: 8. medical-en\n",
      "  unique: 0 files failed\n",
      "  format: 0 files failed\n",
      "  channels: 0 files failed\n",
      "  rate: 0 files failed\n",
      "  transcript: 0 files failed\n",
      "  Total files checked: 3159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def validate_audio_files(main_dir):\n",
    "    subfolders = [f.path for f in os.scandir(main_dir) if f.is_dir()]\n",
    "    summary = {}\n",
    "\n",
    "    for subfolder in subfolders:\n",
    "        subfolder_name = os.path.basename(subfolder)\n",
    "        if os.path.isdir(subfolder):\n",
    "            x = subfolder_name.split('.')[0]\n",
    "            ref_file = os.path.join(subfolder, f\"{x}_reference.stm\")\n",
    "\n",
    "        audio_files = [f for f in os.listdir(subfolder) if f.endswith('.wav')]\n",
    "\n",
    "        unique_files = set()\n",
    "        failed_checks = {\n",
    "            \"unique\": 0,\n",
    "            \"format\": 0,\n",
    "            \"channels\": 0,\n",
    "            \"rate\": 0,\n",
    "            \"transcript\": 0\n",
    "        }\n",
    "        total_files_checked = 0\n",
    "\n",
    "        for audio_file in audio_files:\n",
    "            total_files_checked += 1\n",
    "            file_path = os.path.join(subfolder, audio_file)\n",
    "\n",
    "            #check for unique filenames\n",
    "            if audio_file in unique_files:\n",
    "                failed_checks[\"unique\"] += 1\n",
    "            else:\n",
    "                unique_files.add(audio_file)\n",
    "\n",
    "            #check audio format\n",
    "            try:\n",
    "                with wave.open(file_path, 'rb') as wav_file:\n",
    "                    #check number of channels\n",
    "                    if wav_file.getnchannels() != 1:\n",
    "                        failed_checks[\"channels\"] += 1\n",
    "                    #check sample rate\n",
    "                    if wav_file.getframerate() != 16000:\n",
    "                        failed_checks[\"rate\"] += 1\n",
    "            except wave.Error:\n",
    "                failed_checks[\"format\"] += 1\n",
    "\n",
    "            #check for transcript in reference file\n",
    "            if x != '5':\n",
    "                utt_id = os.path.splitext(audio_file)[0]\n",
    "                with open(ref_file, 'r') as f:\n",
    "                    ref_transcripts = f.readlines()\n",
    "                if not any(utt_id in line for line in ref_transcripts):\n",
    "                    failed_checks[\"transcript\"] += 1\n",
    "\n",
    "        summary[subfolder_name] = failed_checks\n",
    "        summary[subfolder_name][\"total_files_checked\"] = total_files_checked\n",
    "\n",
    "    #print summary\n",
    "    for subfolder_name, checks in summary.items():\n",
    "        print(f\"Subfolder: {subfolder_name}\")\n",
    "        total = checks.pop(\"total_files_checked\", 0)\n",
    "        for check, count in checks.items():\n",
    "            print(f\"  {check}: {count} files failed\")\n",
    "        print(f\"  Total files checked: {total}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "validate_audio_files(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
