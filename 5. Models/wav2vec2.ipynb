{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2fee2fb",
   "metadata": {},
   "source": [
    "Please note: this notebook was designed to be used in a Sagemaker environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5126a9-e531-4dce-afb1-8ac3cbb6f650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15de0e07-1f96-4872-9cb7-403ecf37c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import boto3\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import torchaudio\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e7bea6-148e-4d58-9608-a67bf9c63752",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'your/input/bucket'\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "script_dir = join(os.getcwd())\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9811b5b-acb8-4207-a955-20696e0ebd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s3_client():\n",
    "    return boto3.client('s3')\n",
    "\n",
    "\n",
    "def list_s3_files_folder(folder_name):\n",
    "    if not folder_name.endswith('/'):\n",
    "        folder_name += '/'\n",
    "\n",
    "    keys = []\n",
    "    continuation_token = None\n",
    "\n",
    "    while True:\n",
    "        if continuation_token:\n",
    "            response = s3.list_objects_v2(\n",
    "                Bucket=BUCKET_NAME,\n",
    "                Prefix=folder_name,\n",
    "                ContinuationToken=continuation_token\n",
    "            )\n",
    "        else:\n",
    "            response = s3.list_objects_v2(\n",
    "                Bucket=BUCKET_NAME,\n",
    "                Prefix=folder_name\n",
    "            )\n",
    "\n",
    "        contents = response.get('Contents', [])\n",
    "        keys.extend(\n",
    "            obj['Key'] for obj in contents if obj['Key'].endswith('.wav')\n",
    "        )\n",
    "\n",
    "        if response.get('IsTruncated'):\n",
    "            continuation_token = response.get('NextContinuationToken')\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return keys\n",
    "\n",
    "\n",
    "def get_file(file_name):\n",
    "    buffer = BytesIO()\n",
    "    s3.download_fileobj(BUCKET_NAME, file_name, buffer)\n",
    "    buffer.seek(0)\n",
    "\n",
    "    return buffer\n",
    "\n",
    "\n",
    "def get_reference(folder_name):\n",
    "    if not folder_name.endswith('/'):\n",
    "        folder_name += '/'\n",
    "\n",
    "    x = folder_name.rstrip('/').split('.')[0]\n",
    "    expected_filename = f\"{x}_reference.stm\"\n",
    "    expected_key = folder_name + expected_filename\n",
    "\n",
    "    response = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=folder_name)\n",
    "\n",
    "    for obj in response.get('Contents', []):\n",
    "        if obj['Key'] == expected_key:\n",
    "            buffer = BytesIO()\n",
    "            s3.download_fileobj(BUCKET_NAME, expected_key, buffer)\n",
    "            stm_text = buffer.getvalue().decode(\"utf-8\")\n",
    "            return stm_text\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def list_folders():\n",
    "    response = s3.list_objects_v2(Bucket=BUCKET_NAME, Delimiter='/')\n",
    "    return [p['Prefix'].rstrip('/') for p in response.get('CommonPrefixes', [])]\n",
    "\n",
    "\n",
    "def get_duration(stm_text, s3_key):\n",
    "    # Extract the filename without extension from the full S3 key\n",
    "    clip_base = os.path.splitext(os.path.basename(s3_key))[0]\n",
    "\n",
    "    for line in stm_text.splitlines():\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "\n",
    "        if parts[0] == clip_base:\n",
    "            try:\n",
    "                start = float(parts[3])\n",
    "                end = float(parts[4])\n",
    "                return end - start\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc626ee-7a73-406d-bfa1-4ead7928170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = get_s3_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b05292-5235-49b4-ad8b-5ba2c06033a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_clips_with_models(models):\n",
    "    \"\"\"Predict audio clips using wav2vec2 models and write .ctm + .tsv output per folder.\"\"\"\n",
    "    for model_name in models:\n",
    "        processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "        model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "        model.eval()\n",
    "\n",
    "        device = torch.device(\"cuda\")\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Set up output directories\n",
    "        model_name = model_name.split('/')[-1]\n",
    "        model_dir = Path(\"results\") / model_name\n",
    "        ctm_dir = model_dir / \"ctm\"\n",
    "        tsv_dir = model_dir / \"tsv\"\n",
    "        model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        ctm_dir.mkdir(exist_ok=True)\n",
    "        tsv_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # Progress tracking\n",
    "        progress_file = model_dir / \"progress.tsv\"\n",
    "        completed_folders = set()\n",
    "        if progress_file.exists():\n",
    "            with open(progress_file, \"r\") as pf:\n",
    "                completed_folders = set(line.strip() for line in pf)\n",
    "\n",
    "        folders = list_folders()\n",
    "\n",
    "        for folder in tqdm(folders, desc=f\"{model_name} - folders\", unit=\"folder\", dynamic_ncols=True, position=0):\n",
    "            if folder in completed_folders:\n",
    "                continue\n",
    "\n",
    "            x = folder.rstrip('/').split('.')[0]\n",
    "            files = list_s3_files_folder(folder)\n",
    "\n",
    "            ctm_lines = []\n",
    "            tsv_lines = []\n",
    "            file_sentences = {}\n",
    "\n",
    "            ref_file = get_reference(folder)\n",
    "\n",
    "            for file in tqdm(files, desc=f\"Â  {folder}\", unit=\"file\", leave=False, dynamic_ncols=True, position=1):\n",
    "                audio_buffer = get_file(file)\n",
    "                waveform, sr = torchaudio.load(audio_buffer)\n",
    "                waveform = waveform.squeeze().to(device)\n",
    "                file_id = Path(file).stem\n",
    "\n",
    "                assert sr == SAMPLING_RATE, f\"Expected sampling rate {SAMPLING_RATE}, got {sr} in {file}\"\n",
    "\n",
    "                inputs = processor(waveform, sampling_rate=sr, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "                start_time = time.perf_counter()\n",
    "                with torch.no_grad():\n",
    "                    logits = model(**inputs).logits\n",
    "\n",
    "                pred_ids = torch.argmax(logits, dim=-1)\n",
    "                output = processor.decode(pred_ids[0], output_word_offsets=True)\n",
    "\n",
    "                time_offset = model.config.inputs_to_logits_ratio / processor.feature_extractor.sampling_rate\n",
    "                end_time = time.perf_counter()\n",
    "\n",
    "                words = []\n",
    "\n",
    "                for d in output.word_offsets:\n",
    "                    word = d[\"word\"]\n",
    "                    start = round(d[\"start_offset\"] * time_offset, 2)\n",
    "                    end = round(d[\"end_offset\"] * time_offset, 2)\n",
    "                    duration = round(end - start, 2)\n",
    "\n",
    "                    confidence = d.get(\"score\", 1.0)  # score sometimes not present\n",
    "                    ctm_lines.append(f\"{file_id} 1 {start:.2f} {duration:.2f} {word} {confidence:.4f}\")\n",
    "                    words.append(word)\n",
    "\n",
    "                    duration = get_duration(ref_file, file)\n",
    "\n",
    "                execution_time = end_time - start_time\n",
    "                rtf = f\"{(execution_time / duration):.4f}\"\n",
    "\n",
    "                prediction = \" \".join(words)\n",
    "                file_sentences[file_id] = prediction\n",
    "\n",
    "                tsv_lines.append(f\"{file_id}\\t{rtf}\\t{prediction}\")\n",
    "\n",
    "            safe_folder_name = folder.split(\".\")[0]\n",
    "            ctm_filename = f\"{model_name}_{safe_folder_name}.ctm\"\n",
    "            tsv_filename = f\"{model_name}_{safe_folder_name}.tsv\"\n",
    "\n",
    "            with open(ctm_dir / ctm_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"\\n\".join(ctm_lines) + \"\\n\")\n",
    "\n",
    "            with open(tsv_dir / tsv_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"file\\tRTF\\tprediction\\n\")  # TSV header\n",
    "                f.write(\"\\n\".join(tsv_lines) + \"\\n\")\n",
    "\n",
    "            # Mark this folder as completed\n",
    "            with open(progress_file, \"a\") as pf:\n",
    "                pf.write(folder + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c3558-20ad-4062-8802-286a81f15b3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_to_test = [\"jonatasgrosman/wav2vec2-large-xlsr-53-dutch\", \"GroNLP/wav2vec2-dutch-large-ft-cgn\"]\n",
    "\n",
    "predict_clips_with_models(models_to_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
